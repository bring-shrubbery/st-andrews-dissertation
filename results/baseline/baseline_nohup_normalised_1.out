WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
2020-08-13 20:11:04.822469: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1698693120 exceeds 10% of free system memory.
2020-08-13 20:11:07.497722: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.78GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-13 20:11:07.607611: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-13 20:11:07.647526: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-13 20:11:07.755585: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-13 20:11:07.767314: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-13 20:11:07.795656: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.13GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-13 20:11:07.836131: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.11GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-13 20:11:08.025633: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.78GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-13 20:11:08.140135: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.78GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-13 20:14:47.180714: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1073741824 exceeds 10% of free system memory.
2020-08-13 20:14:48.271146: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1073741824 exceeds 10% of free system memory.
2020-08-13 20:14:48.573959: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1073741824 exceeds 10% of free system memory.
Preparing...
Loading dataset...
0.656169760198232 0.0
0.6522436679966424 0.0
0.656169760198232 0.0
0.6522436679966424 0.0
Creating the model...
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 502, 502, 96)      11712     
_________________________________________________________________
batch_normalization (BatchNo (None, 502, 502, 96)      384       
_________________________________________________________________
activation (Activation)      (None, 502, 502, 96)      0         
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 167, 167, 96)      0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 163, 163, 384)     921984    
_________________________________________________________________
activation_1 (Activation)    (None, 163, 163, 384)     0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 54, 54, 384)       0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 52, 52, 384)       1327488   
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 50, 50, 256)       884992    
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 48, 48, 256)       590080    
_________________________________________________________________
activation_2 (Activation)    (None, 48, 48, 256)       0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 16, 16, 256)       0         
_________________________________________________________________
flatten (Flatten)            (None, 65536)             0         
_________________________________________________________________
dense (Dense)                (None, 4096)              268439552 
_________________________________________________________________
dropout (Dropout)            (None, 4096)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 4096)              16781312  
_________________________________________________________________
dropout_1 (Dropout)          (None, 4096)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 4097      
=================================================================
Total params: 288,961,601
Trainable params: 288,961,409
Non-trainable params: 192
_________________________________________________________________
None
Training the model...
Epoch 1/100

Epoch 00001: val_loss improved from inf to 6.00633, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 223s - loss: 8.5637 - accuracy: 0.4988 - mse: 0.4234 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 6.0063 - val_accuracy: 0.5000 - val_mse: 0.3736 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05
2020-08-13 20:18:31.713645: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1073741824 exceeds 10% of free system memory.
Epoch 2/100

Epoch 00002: val_loss improved from 6.00633 to 3.27541, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 224s - loss: 4.4766 - accuracy: 0.5414 - mse: 0.3710 - precision: 0.6959 - recall: 0.1469 - val_loss: 3.2754 - val_accuracy: 0.5139 - val_mse: 0.4089 - val_precision: 1.0000 - val_recall: 0.0278 - lr: 1.0000e-05
Epoch 3/100

Epoch 00003: val_loss improved from 3.27541 to 2.01094, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 224s - loss: 2.5520 - accuracy: 0.6000 - mse: 0.3129 - precision: 0.7355 - recall: 0.3123 - val_loss: 2.0109 - val_accuracy: 0.5167 - val_mse: 0.4081 - val_precision: 1.0000 - val_recall: 0.0333 - lr: 1.0000e-05
Epoch 4/100

Epoch 00004: val_loss improved from 2.01094 to 1.45222, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 224s - loss: 1.6770 - accuracy: 0.6296 - mse: 0.3193 - precision: 0.7966 - recall: 0.3481 - val_loss: 1.4522 - val_accuracy: 0.5417 - val_mse: 0.4080 - val_precision: 1.0000 - val_recall: 0.0833 - lr: 1.0000e-05
Epoch 5/100

Epoch 00005: val_loss improved from 1.45222 to 1.15213, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 224s - loss: 1.2695 - accuracy: 0.7142 - mse: 0.2425 - precision: 0.8747 - recall: 0.5000 - val_loss: 1.1521 - val_accuracy: 0.7917 - val_mse: 0.1716 - val_precision: 0.9134 - val_recall: 0.6444 - lr: 1.0000e-05
Epoch 6/100

Epoch 00006: val_loss improved from 1.15213 to 1.08513, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 224s - loss: 1.0845 - accuracy: 0.7735 - mse: 0.1934 - precision: 0.9251 - recall: 0.5951 - val_loss: 1.0851 - val_accuracy: 0.6167 - val_mse: 0.3583 - val_precision: 1.0000 - val_recall: 0.2333 - lr: 1.0000e-05
Epoch 7/100

Epoch 00007: val_loss improved from 1.08513 to 0.96596, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 224s - loss: 0.9810 - accuracy: 0.8111 - mse: 0.1680 - precision: 0.9484 - recall: 0.6580 - val_loss: 0.9660 - val_accuracy: 0.7333 - val_mse: 0.2027 - val_precision: 0.9375 - val_recall: 0.5000 - lr: 1.0000e-05
Epoch 8/100

Epoch 00008: val_loss improved from 0.96596 to 0.90258, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 224s - loss: 0.9068 - accuracy: 0.8475 - mse: 0.1420 - precision: 0.9684 - recall: 0.7185 - val_loss: 0.9026 - val_accuracy: 0.7917 - val_mse: 0.1739 - val_precision: 0.9339 - val_recall: 0.6278 - lr: 1.0000e-05
Epoch 9/100

Epoch 00009: val_loss improved from 0.90258 to 0.89536, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 224s - loss: 0.8519 - accuracy: 0.8630 - mse: 0.1300 - precision: 0.9788 - recall: 0.7420 - val_loss: 0.8954 - val_accuracy: 0.7056 - val_mse: 0.2377 - val_precision: 0.8491 - val_recall: 0.5000 - lr: 1.0000e-05
Epoch 10/100

Epoch 00010: val_loss improved from 0.89536 to 0.87679, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 225s - loss: 0.8110 - accuracy: 0.8660 - mse: 0.1243 - precision: 0.9853 - recall: 0.7432 - val_loss: 0.8768 - val_accuracy: 0.6972 - val_mse: 0.2649 - val_precision: 0.7630 - val_recall: 0.5722 - lr: 1.0000e-05
Epoch 11/100

Epoch 00011: val_loss improved from 0.87679 to 0.84000, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 225s - loss: 0.7717 - accuracy: 0.8864 - mse: 0.1056 - precision: 0.9860 - recall: 0.7840 - val_loss: 0.8400 - val_accuracy: 0.6972 - val_mse: 0.2523 - val_precision: 0.8087 - val_recall: 0.5167 - lr: 1.0000e-05
Epoch 12/100

Epoch 00012: val_loss improved from 0.84000 to 0.82994, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 226s - loss: 0.7426 - accuracy: 0.8914 - mse: 0.1002 - precision: 0.9818 - recall: 0.7975 - val_loss: 0.8299 - val_accuracy: 0.6694 - val_mse: 0.2655 - val_precision: 0.7402 - val_recall: 0.5222 - lr: 1.0000e-05
Epoch 13/100

Epoch 00013: val_loss improved from 0.82994 to 0.79912, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 227s - loss: 0.7150 - accuracy: 0.9025 - mse: 0.0909 - precision: 0.9866 - recall: 0.8160 - val_loss: 0.7991 - val_accuracy: 0.7278 - val_mse: 0.2223 - val_precision: 0.7500 - val_recall: 0.6833 - lr: 1.0000e-05
Epoch 14/100

Epoch 00014: val_loss did not improve from 0.79912
810/810 - 220s - loss: 0.6922 - accuracy: 0.9105 - mse: 0.0845 - precision: 0.9897 - recall: 0.8296 - val_loss: 0.8309 - val_accuracy: 0.5667 - val_mse: 0.3760 - val_precision: 0.6200 - val_recall: 0.3444 - lr: 1.0000e-05
Epoch 15/100

Epoch 00015: val_loss improved from 0.79912 to 0.78228, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 227s - loss: 0.6748 - accuracy: 0.9123 - mse: 0.0807 - precision: 0.9941 - recall: 0.8296 - val_loss: 0.7823 - val_accuracy: 0.6861 - val_mse: 0.2369 - val_precision: 0.6634 - val_recall: 0.7556 - lr: 1.0000e-05
Epoch 16/100

Epoch 00016: val_loss did not improve from 0.78228
810/810 - 220s - loss: 0.6590 - accuracy: 0.9210 - mse: 0.0742 - precision: 0.9816 - recall: 0.8580 - val_loss: 0.7838 - val_accuracy: 0.6417 - val_mse: 0.2796 - val_precision: 0.6527 - val_recall: 0.6056 - lr: 1.0000e-05
Epoch 17/100

Epoch 00017: val_loss did not improve from 0.78228
810/810 - 220s - loss: 0.6406 - accuracy: 0.9333 - mse: 0.0647 - precision: 0.9972 - recall: 0.8691 - val_loss: 0.8020 - val_accuracy: 0.5389 - val_mse: 0.3806 - val_precision: 0.5565 - val_recall: 0.3833 - lr: 1.0000e-05
Epoch 18/100

Epoch 00018: val_loss improved from 0.78228 to 0.77705, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 226s - loss: 0.6261 - accuracy: 0.9383 - mse: 0.0592 - precision: 0.9958 - recall: 0.8802 - val_loss: 0.7771 - val_accuracy: 0.5889 - val_mse: 0.3211 - val_precision: 0.5889 - val_recall: 0.5889 - lr: 1.0000e-05
Epoch 19/100

Epoch 00019: val_loss improved from 0.77705 to 0.77328, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 226s - loss: 0.6187 - accuracy: 0.9346 - mse: 0.0621 - precision: 0.9958 - recall: 0.8728 - val_loss: 0.7733 - val_accuracy: 0.5972 - val_mse: 0.3312 - val_precision: 0.6000 - val_recall: 0.5833 - lr: 1.0000e-05
Epoch 20/100

Epoch 00020: val_loss improved from 0.77328 to 0.75365, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 226s - loss: 0.6036 - accuracy: 0.9488 - mse: 0.0487 - precision: 0.9986 - recall: 0.8988 - val_loss: 0.7537 - val_accuracy: 0.6361 - val_mse: 0.2889 - val_precision: 0.6219 - val_recall: 0.6944 - lr: 1.0000e-05
Epoch 21/100

Epoch 00021: val_loss did not improve from 0.75365
810/810 - 220s - loss: 0.5951 - accuracy: 0.9525 - mse: 0.0455 - precision: 0.9986 - recall: 0.9062 - val_loss: 0.7548 - val_accuracy: 0.6444 - val_mse: 0.2974 - val_precision: 0.6102 - val_recall: 0.8000 - lr: 1.0000e-05
Epoch 22/100

Epoch 00022: val_loss improved from 0.75365 to 0.74854, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 226s - loss: 0.5860 - accuracy: 0.9574 - mse: 0.0402 - precision: 0.9973 - recall: 0.9173 - val_loss: 0.7485 - val_accuracy: 0.6167 - val_mse: 0.3128 - val_precision: 0.6061 - val_recall: 0.6667 - lr: 1.0000e-05
Epoch 23/100

Epoch 00023: val_loss improved from 0.74854 to 0.73202, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 227s - loss: 0.5806 - accuracy: 0.9562 - mse: 0.0420 - precision: 0.9946 - recall: 0.9173 - val_loss: 0.7320 - val_accuracy: 0.6722 - val_mse: 0.2646 - val_precision: 0.6240 - val_recall: 0.8667 - lr: 1.0000e-05
Epoch 24/100

Epoch 00024: val_loss did not improve from 0.73202
810/810 - 220s - loss: 0.5706 - accuracy: 0.9654 - mse: 0.0339 - precision: 0.9987 - recall: 0.9321 - val_loss: 0.7541 - val_accuracy: 0.5639 - val_mse: 0.3614 - val_precision: 0.5602 - val_recall: 0.5944 - lr: 1.0000e-05
Epoch 25/100

Epoch 00025: val_loss improved from 0.73202 to 0.73083, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 227s - loss: 0.5652 - accuracy: 0.9648 - mse: 0.0339 - precision: 0.9974 - recall: 0.9321 - val_loss: 0.7308 - val_accuracy: 0.6278 - val_mse: 0.2983 - val_precision: 0.6018 - val_recall: 0.7556 - lr: 1.0000e-05
Epoch 26/100

Epoch 00026: val_loss improved from 0.73083 to 0.72853, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 225s - loss: 0.5595 - accuracy: 0.9642 - mse: 0.0349 - precision: 1.0000 - recall: 0.9284 - val_loss: 0.7285 - val_accuracy: 0.6194 - val_mse: 0.3178 - val_precision: 0.6029 - val_recall: 0.7000 - lr: 1.0000e-05
Epoch 27/100

Epoch 00027: val_loss improved from 0.72853 to 0.70602, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 226s - loss: 0.5544 - accuracy: 0.9660 - mse: 0.0321 - precision: 0.9961 - recall: 0.9358 - val_loss: 0.7060 - val_accuracy: 0.6889 - val_mse: 0.2524 - val_precision: 0.6349 - val_recall: 0.8889 - lr: 1.0000e-05
Epoch 28/100

Epoch 00028: val_loss did not improve from 0.70602
810/810 - 220s - loss: 0.5530 - accuracy: 0.9642 - mse: 0.0354 - precision: 0.9987 - recall: 0.9296 - val_loss: 0.7205 - val_accuracy: 0.6083 - val_mse: 0.3099 - val_precision: 0.5951 - val_recall: 0.6778 - lr: 1.0000e-05
Epoch 29/100

Epoch 00029: val_loss did not improve from 0.70602
810/810 - 220s - loss: 0.5486 - accuracy: 0.9679 - mse: 0.0304 - precision: 0.9948 - recall: 0.9407 - val_loss: 0.7228 - val_accuracy: 0.5889 - val_mse: 0.3209 - val_precision: 0.5816 - val_recall: 0.6333 - lr: 1.0000e-05
Epoch 30/100

Epoch 00030: val_loss did not improve from 0.70602
810/810 - 220s - loss: 0.5453 - accuracy: 0.9691 - mse: 0.0293 - precision: 0.9987 - recall: 0.9395 - val_loss: 0.7160 - val_accuracy: 0.6417 - val_mse: 0.3076 - val_precision: 0.6164 - val_recall: 0.7500 - lr: 1.0000e-05
Epoch 31/100

Epoch 00031: val_loss improved from 0.70602 to 0.70576, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 227s - loss: 0.5396 - accuracy: 0.9753 - mse: 0.0245 - precision: 1.0000 - recall: 0.9506 - val_loss: 0.7058 - val_accuracy: 0.6389 - val_mse: 0.2790 - val_precision: 0.6106 - val_recall: 0.7667 - lr: 1.0000e-05
Epoch 32/100

Epoch 00032: val_loss did not improve from 0.70576
810/810 - 220s - loss: 0.5414 - accuracy: 0.9691 - mse: 0.0297 - precision: 0.9974 - recall: 0.9407 - val_loss: 0.7222 - val_accuracy: 0.5750 - val_mse: 0.3255 - val_precision: 0.5659 - val_recall: 0.6444 - lr: 1.0000e-05
Epoch 33/100

Epoch 00033: val_loss did not improve from 0.70576
810/810 - 220s - loss: 0.5391 - accuracy: 0.9716 - mse: 0.0269 - precision: 0.9987 - recall: 0.9444 - val_loss: 0.7138 - val_accuracy: 0.6111 - val_mse: 0.3106 - val_precision: 0.5926 - val_recall: 0.7111 - lr: 1.0000e-05
Epoch 34/100

Epoch 00034: val_loss improved from 0.70576 to 0.70278, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 227s - loss: 0.5335 - accuracy: 0.9778 - mse: 0.0222 - precision: 1.0000 - recall: 0.9556 - val_loss: 0.7028 - val_accuracy: 0.6444 - val_mse: 0.2837 - val_precision: 0.6130 - val_recall: 0.7833 - lr: 1.0000e-05
Epoch 35/100

Epoch 00035: val_loss did not improve from 0.70278
810/810 - 220s - loss: 0.5328 - accuracy: 0.9765 - mse: 0.0230 - precision: 1.0000 - recall: 0.9531 - val_loss: 0.7338 - val_accuracy: 0.5111 - val_mse: 0.3985 - val_precision: 0.5139 - val_recall: 0.4111 - lr: 1.0000e-05
Epoch 36/100

Epoch 00036: val_loss did not improve from 0.70278
810/810 - 220s - loss: 0.5318 - accuracy: 0.9778 - mse: 0.0226 - precision: 0.9987 - recall: 0.9568 - val_loss: 0.7088 - val_accuracy: 0.6250 - val_mse: 0.3124 - val_precision: 0.6098 - val_recall: 0.6944 - lr: 1.0000e-05
Epoch 37/100

Epoch 00037: val_loss improved from 0.70278 to 0.70193, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 226s - loss: 0.5283 - accuracy: 0.9790 - mse: 0.0209 - precision: 1.0000 - recall: 0.9580 - val_loss: 0.7019 - val_accuracy: 0.6000 - val_mse: 0.2880 - val_precision: 0.5891 - val_recall: 0.6611 - lr: 1.0000e-05
Epoch 38/100

Epoch 00038: val_loss did not improve from 0.70193
810/810 - 219s - loss: 0.5300 - accuracy: 0.9741 - mse: 0.0236 - precision: 0.9974 - recall: 0.9506 - val_loss: 0.7273 - val_accuracy: 0.5639 - val_mse: 0.3692 - val_precision: 0.5596 - val_recall: 0.6000 - lr: 1.0000e-05
Epoch 39/100

Epoch 00039: val_loss did not improve from 0.70193
810/810 - 220s - loss: 0.5260 - accuracy: 0.9809 - mse: 0.0191 - precision: 1.0000 - recall: 0.9617 - val_loss: 0.7041 - val_accuracy: 0.6250 - val_mse: 0.3000 - val_precision: 0.5991 - val_recall: 0.7556 - lr: 1.0000e-05
Epoch 40/100

Epoch 00040: val_loss improved from 0.70193 to 0.69851, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 227s - loss: 0.5243 - accuracy: 0.9815 - mse: 0.0185 - precision: 1.0000 - recall: 0.9630 - val_loss: 0.6985 - val_accuracy: 0.6194 - val_mse: 0.2932 - val_precision: 0.6000 - val_recall: 0.7167 - lr: 1.0000e-05
Epoch 41/100

Epoch 00041: val_loss did not improve from 0.69851
810/810 - 219s - loss: 0.5248 - accuracy: 0.9784 - mse: 0.0204 - precision: 0.9987 - recall: 0.9580 - val_loss: 0.7045 - val_accuracy: 0.6306 - val_mse: 0.3084 - val_precision: 0.6063 - val_recall: 0.7444 - lr: 1.0000e-05
Epoch 42/100

Epoch 00042: val_loss did not improve from 0.69851
810/810 - 219s - loss: 0.5228 - accuracy: 0.9821 - mse: 0.0178 - precision: 1.0000 - recall: 0.9642 - val_loss: 0.7099 - val_accuracy: 0.5889 - val_mse: 0.3253 - val_precision: 0.5792 - val_recall: 0.6500 - lr: 1.0000e-05
Epoch 43/100

Epoch 00043: val_loss did not improve from 0.69851
810/810 - 219s - loss: 0.5210 - accuracy: 0.9827 - mse: 0.0173 - precision: 1.0000 - recall: 0.9654 - val_loss: 0.7043 - val_accuracy: 0.6028 - val_mse: 0.3100 - val_precision: 0.5902 - val_recall: 0.6722 - lr: 1.0000e-05
Epoch 44/100

Epoch 00044: val_loss did not improve from 0.69851
810/810 - 219s - loss: 0.5225 - accuracy: 0.9809 - mse: 0.0193 - precision: 0.9987 - recall: 0.9630 - val_loss: 0.7016 - val_accuracy: 0.5972 - val_mse: 0.3043 - val_precision: 0.5814 - val_recall: 0.6944 - lr: 1.0000e-05
Epoch 45/100

Epoch 00045: val_loss did not improve from 0.69851
810/810 - 220s - loss: 0.5203 - accuracy: 0.9827 - mse: 0.0173 - precision: 1.0000 - recall: 0.9654 - val_loss: 0.7018 - val_accuracy: 0.6083 - val_mse: 0.3105 - val_precision: 0.5933 - val_recall: 0.6889 - lr: 1.0000e-05
Epoch 46/100

Epoch 00046: val_loss did not improve from 0.69851
810/810 - 219s - loss: 0.5222 - accuracy: 0.9790 - mse: 0.0196 - precision: 0.9962 - recall: 0.9617 - val_loss: 0.7076 - val_accuracy: 0.5917 - val_mse: 0.3164 - val_precision: 0.5767 - val_recall: 0.6889 - lr: 1.0000e-05
Epoch 47/100

Epoch 00047: val_loss did not improve from 0.69851
810/810 - 219s - loss: 0.5193 - accuracy: 0.9827 - mse: 0.0173 - precision: 1.0000 - recall: 0.9654 - val_loss: 0.7050 - val_accuracy: 0.6028 - val_mse: 0.3131 - val_precision: 0.5869 - val_recall: 0.6944 - lr: 1.0000e-05
Epoch 48/100

Epoch 00048: val_loss did not improve from 0.69851
810/810 - 219s - loss: 0.5186 - accuracy: 0.9827 - mse: 0.0173 - precision: 1.0000 - recall: 0.9654 - val_loss: 0.7056 - val_accuracy: 0.5917 - val_mse: 0.3139 - val_precision: 0.5789 - val_recall: 0.6722 - lr: 1.0000e-05
Epoch 49/100

Epoch 00049: val_loss did not improve from 0.69851
810/810 - 219s - loss: 0.5217 - accuracy: 0.9778 - mse: 0.0216 - precision: 0.9974 - recall: 0.9580 - val_loss: 0.7148 - val_accuracy: 0.6167 - val_mse: 0.3317 - val_precision: 0.5913 - val_recall: 0.7556 - lr: 1.0000e-05
Epoch 50/100

Epoch 00050: val_loss did not improve from 0.69851
810/810 - 220s - loss: 0.5186 - accuracy: 0.9833 - mse: 0.0166 - precision: 1.0000 - recall: 0.9667 - val_loss: 0.7055 - val_accuracy: 0.6083 - val_mse: 0.3193 - val_precision: 0.5907 - val_recall: 0.7056 - lr: 1.0000e-05
Epoch 51/100

Epoch 00051: val_loss did not improve from 0.69851
810/810 - 220s - loss: 0.5174 - accuracy: 0.9840 - mse: 0.0160 - precision: 1.0000 - recall: 0.9679 - val_loss: 0.7085 - val_accuracy: 0.5944 - val_mse: 0.3345 - val_precision: 0.5842 - val_recall: 0.6556 - lr: 1.0000e-05
Epoch 52/100

Epoch 00052: val_loss did not improve from 0.69851
810/810 - 220s - loss: 0.5168 - accuracy: 0.9840 - mse: 0.0161 - precision: 1.0000 - recall: 0.9679 - val_loss: 0.7034 - val_accuracy: 0.6167 - val_mse: 0.3178 - val_precision: 0.5963 - val_recall: 0.7222 - lr: 1.0000e-05
Epoch 53/100

Epoch 00053: val_loss improved from 0.69851 to 0.68912, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 227s - loss: 0.5187 - accuracy: 0.9809 - mse: 0.0180 - precision: 0.9962 - recall: 0.9654 - val_loss: 0.6891 - val_accuracy: 0.6528 - val_mse: 0.2674 - val_precision: 0.6132 - val_recall: 0.8278 - lr: 1.0000e-05
Epoch 54/100

Epoch 00054: val_loss did not improve from 0.68912
810/810 - 220s - loss: 0.5167 - accuracy: 0.9852 - mse: 0.0149 - precision: 1.0000 - recall: 0.9704 - val_loss: 0.7143 - val_accuracy: 0.5694 - val_mse: 0.3534 - val_precision: 0.5661 - val_recall: 0.5944 - lr: 1.0000e-05
Epoch 55/100

Epoch 00055: val_loss did not improve from 0.68912
810/810 - 220s - loss: 0.5157 - accuracy: 0.9852 - mse: 0.0148 - precision: 1.0000 - recall: 0.9704 - val_loss: 0.6939 - val_accuracy: 0.6389 - val_mse: 0.2795 - val_precision: 0.6025 - val_recall: 0.8167 - lr: 1.0000e-05
Epoch 56/100

Epoch 00056: val_loss did not improve from 0.68912
810/810 - 220s - loss: 0.5157 - accuracy: 0.9852 - mse: 0.0149 - precision: 1.0000 - recall: 0.9704 - val_loss: 0.7019 - val_accuracy: 0.6250 - val_mse: 0.3157 - val_precision: 0.6037 - val_recall: 0.7278 - lr: 1.0000e-05
Epoch 57/100

Epoch 00057: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5148 - accuracy: 0.9852 - mse: 0.0148 - precision: 1.0000 - recall: 0.9704 - val_loss: 0.7058 - val_accuracy: 0.6028 - val_mse: 0.3264 - val_precision: 0.5837 - val_recall: 0.7167 - lr: 1.0000e-05
Epoch 58/100

Epoch 00058: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5162 - accuracy: 0.9846 - mse: 0.0158 - precision: 1.0000 - recall: 0.9691 - val_loss: 0.7130 - val_accuracy: 0.6028 - val_mse: 0.3450 - val_precision: 0.5860 - val_recall: 0.7000 - lr: 1.0000e-05
Epoch 59/100

Epoch 00059: val_loss did not improve from 0.68912
810/810 - 220s - loss: 0.5148 - accuracy: 0.9852 - mse: 0.0148 - precision: 1.0000 - recall: 0.9704 - val_loss: 0.7144 - val_accuracy: 0.5694 - val_mse: 0.3451 - val_precision: 0.5635 - val_recall: 0.6167 - lr: 1.0000e-05
Epoch 60/100

Epoch 00060: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5145 - accuracy: 0.9852 - mse: 0.0146 - precision: 1.0000 - recall: 0.9704 - val_loss: 0.7123 - val_accuracy: 0.5861 - val_mse: 0.3419 - val_precision: 0.5756 - val_recall: 0.6556 - lr: 1.0000e-05
Epoch 61/100

Epoch 00061: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5166 - accuracy: 0.9833 - mse: 0.0159 - precision: 0.9975 - recall: 0.9691 - val_loss: 0.7006 - val_accuracy: 0.6333 - val_mse: 0.3183 - val_precision: 0.6081 - val_recall: 0.7500 - lr: 1.0000e-05
Epoch 62/100

Epoch 00062: val_loss did not improve from 0.68912
810/810 - 220s - loss: 0.5143 - accuracy: 0.9864 - mse: 0.0135 - precision: 1.0000 - recall: 0.9728 - val_loss: 0.6993 - val_accuracy: 0.6250 - val_mse: 0.3135 - val_precision: 0.6056 - val_recall: 0.7167 - lr: 1.0000e-05
Epoch 63/100

Epoch 00063: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5141 - accuracy: 0.9870 - mse: 0.0131 - precision: 1.0000 - recall: 0.9741 - val_loss: 0.7101 - val_accuracy: 0.5889 - val_mse: 0.3534 - val_precision: 0.5816 - val_recall: 0.6333 - lr: 1.0000e-05
Epoch 64/100

Epoch 00064: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5136 - accuracy: 0.9877 - mse: 0.0124 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.6946 - val_accuracy: 0.6278 - val_mse: 0.3028 - val_precision: 0.6055 - val_recall: 0.7333 - lr: 1.0000e-05
Epoch 65/100

Epoch 00065: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5129 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7026 - val_accuracy: 0.6194 - val_mse: 0.3214 - val_precision: 0.5991 - val_recall: 0.7222 - lr: 1.0000e-05
Epoch 66/100

Epoch 00066: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5158 - accuracy: 0.9827 - mse: 0.0154 - precision: 0.9962 - recall: 0.9691 - val_loss: 0.6910 - val_accuracy: 0.6333 - val_mse: 0.3008 - val_precision: 0.6121 - val_recall: 0.7278 - lr: 1.0000e-05
Epoch 67/100

Epoch 00067: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5129 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.6963 - val_accuracy: 0.6222 - val_mse: 0.3120 - val_precision: 0.6048 - val_recall: 0.7056 - lr: 1.0000e-05
Epoch 68/100

Epoch 00068: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5126 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.6952 - val_accuracy: 0.6306 - val_mse: 0.3066 - val_precision: 0.6073 - val_recall: 0.7389 - lr: 1.0000e-05
Epoch 69/100

Epoch 00069: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5143 - accuracy: 0.9846 - mse: 0.0148 - precision: 0.9987 - recall: 0.9704 - val_loss: 0.7088 - val_accuracy: 0.6111 - val_mse: 0.3404 - val_precision: 0.5917 - val_recall: 0.7167 - lr: 1.0000e-05
Epoch 70/100

Epoch 00070: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5128 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7040 - val_accuracy: 0.6250 - val_mse: 0.3278 - val_precision: 0.6018 - val_recall: 0.7389 - lr: 1.0000e-05
Epoch 71/100

Epoch 00071: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5124 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7063 - val_accuracy: 0.6139 - val_mse: 0.3297 - val_precision: 0.5919 - val_recall: 0.7333 - lr: 1.0000e-05
Epoch 72/100

Epoch 00072: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5135 - accuracy: 0.9864 - mse: 0.0135 - precision: 1.0000 - recall: 0.9728 - val_loss: 0.7099 - val_accuracy: 0.5889 - val_mse: 0.3456 - val_precision: 0.5755 - val_recall: 0.6778 - lr: 1.0000e-05
Epoch 73/100

Epoch 00073: val_loss did not improve from 0.68912

Epoch 00073: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.
810/810 - 219s - loss: 0.5124 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7010 - val_accuracy: 0.6194 - val_mse: 0.3176 - val_precision: 0.5973 - val_recall: 0.7333 - lr: 1.0000e-05
Epoch 74/100

Epoch 00074: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5121 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7022 - val_accuracy: 0.6167 - val_mse: 0.3214 - val_precision: 0.5946 - val_recall: 0.7333 - lr: 1.0000e-06
Epoch 75/100

Epoch 00075: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5121 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7023 - val_accuracy: 0.6167 - val_mse: 0.3220 - val_precision: 0.5946 - val_recall: 0.7333 - lr: 1.0000e-06
Epoch 76/100

Epoch 00076: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5120 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7013 - val_accuracy: 0.6167 - val_mse: 0.3197 - val_precision: 0.5946 - val_recall: 0.7333 - lr: 1.0000e-06
Epoch 77/100

Epoch 00077: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5119 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7030 - val_accuracy: 0.6167 - val_mse: 0.3247 - val_precision: 0.5946 - val_recall: 0.7333 - lr: 1.0000e-06
Epoch 78/100

Epoch 00078: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5119 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7059 - val_accuracy: 0.6167 - val_mse: 0.3331 - val_precision: 0.5946 - val_recall: 0.7333 - lr: 1.0000e-06
Epoch 79/100

Epoch 00079: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5118 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7004 - val_accuracy: 0.6167 - val_mse: 0.3176 - val_precision: 0.5946 - val_recall: 0.7333 - lr: 1.0000e-06
Epoch 80/100

Epoch 00080: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5117 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7029 - val_accuracy: 0.6139 - val_mse: 0.3241 - val_precision: 0.5919 - val_recall: 0.7333 - lr: 1.0000e-06
Epoch 81/100

Epoch 00081: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5117 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7048 - val_accuracy: 0.6111 - val_mse: 0.3307 - val_precision: 0.5909 - val_recall: 0.7222 - lr: 1.0000e-06
Epoch 82/100

Epoch 00082: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5116 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7033 - val_accuracy: 0.6139 - val_mse: 0.3262 - val_precision: 0.5928 - val_recall: 0.7278 - lr: 1.0000e-06
Epoch 83/100

Epoch 00083: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5115 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7058 - val_accuracy: 0.6056 - val_mse: 0.3316 - val_precision: 0.5848 - val_recall: 0.7278 - lr: 1.0000e-06
Epoch 84/100

Epoch 00084: val_loss did not improve from 0.68912
810/810 - 220s - loss: 0.5115 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7051 - val_accuracy: 0.6111 - val_mse: 0.3302 - val_precision: 0.5901 - val_recall: 0.7278 - lr: 1.0000e-06
Epoch 85/100

Epoch 00085: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5114 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7065 - val_accuracy: 0.6167 - val_mse: 0.3324 - val_precision: 0.5938 - val_recall: 0.7389 - lr: 1.0000e-06
Epoch 86/100

Epoch 00086: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5114 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7046 - val_accuracy: 0.6111 - val_mse: 0.3274 - val_precision: 0.5893 - val_recall: 0.7333 - lr: 1.0000e-06
Epoch 87/100

Epoch 00087: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5114 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7063 - val_accuracy: 0.6139 - val_mse: 0.3342 - val_precision: 0.5928 - val_recall: 0.7278 - lr: 1.0000e-06
Epoch 88/100

Epoch 00088: val_loss did not improve from 0.68912
810/810 - 220s - loss: 0.5113 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7036 - val_accuracy: 0.6083 - val_mse: 0.3262 - val_precision: 0.5859 - val_recall: 0.7389 - lr: 1.0000e-06
Epoch 89/100

Epoch 00089: val_loss did not improve from 0.68912
810/810 - 220s - loss: 0.5113 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7067 - val_accuracy: 0.6028 - val_mse: 0.3356 - val_precision: 0.5845 - val_recall: 0.7111 - lr: 1.0000e-06
Epoch 90/100

Epoch 00090: val_loss did not improve from 0.68912
810/810 - 220s - loss: 0.5112 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7096 - val_accuracy: 0.6056 - val_mse: 0.3420 - val_precision: 0.5864 - val_recall: 0.7167 - lr: 1.0000e-06
Epoch 91/100

Epoch 00091: val_loss did not improve from 0.68912
810/810 - 220s - loss: 0.5112 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7068 - val_accuracy: 0.6083 - val_mse: 0.3346 - val_precision: 0.5874 - val_recall: 0.7278 - lr: 1.0000e-06
Epoch 92/100

Epoch 00092: val_loss did not improve from 0.68912
810/810 - 220s - loss: 0.5112 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7056 - val_accuracy: 0.6111 - val_mse: 0.3319 - val_precision: 0.5909 - val_recall: 0.7222 - lr: 1.0000e-06
Epoch 93/100

Epoch 00093: val_loss did not improve from 0.68912

Epoch 00093: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.
810/810 - 220s - loss: 0.5111 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7061 - val_accuracy: 0.6056 - val_mse: 0.3338 - val_precision: 0.5864 - val_recall: 0.7167 - lr: 1.0000e-06
Epoch 94/100

Epoch 00094: val_loss did not improve from 0.68912
810/810 - 220s - loss: 0.5111 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7062 - val_accuracy: 0.6028 - val_mse: 0.3337 - val_precision: 0.5837 - val_recall: 0.7167 - lr: 1.0000e-07
Epoch 95/100

Epoch 00095: val_loss did not improve from 0.68912
810/810 - 220s - loss: 0.5111 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7056 - val_accuracy: 0.6056 - val_mse: 0.3322 - val_precision: 0.5856 - val_recall: 0.7222 - lr: 1.0000e-07
Epoch 96/100

Epoch 00096: val_loss did not improve from 0.68912
810/810 - 219s - loss: 0.5111 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7053 - val_accuracy: 0.6056 - val_mse: 0.3315 - val_precision: 0.5856 - val_recall: 0.7222 - lr: 1.0000e-07
Epoch 97/100

Epoch 00097: val_loss did not improve from 0.68912
810/810 - 220s - loss: 0.5111 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7052 - val_accuracy: 0.6083 - val_mse: 0.3313 - val_precision: 0.5882 - val_recall: 0.7222 - lr: 1.0000e-07
Epoch 98/100

Epoch 00098: val_loss did not improve from 0.68912
810/810 - 220s - loss: 0.5111 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7056 - val_accuracy: 0.6056 - val_mse: 0.3322 - val_precision: 0.5856 - val_recall: 0.7222 - lr: 1.0000e-07
Epoch 99/100

Epoch 00099: val_loss did not improve from 0.68912
810/810 - 220s - loss: 0.5111 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7060 - val_accuracy: 0.6056 - val_mse: 0.3331 - val_precision: 0.5856 - val_recall: 0.7222 - lr: 1.0000e-07
Epoch 100/100

Epoch 00100: val_loss did not improve from 0.68912
810/810 - 220s - loss: 0.5111 - accuracy: 0.9877 - mse: 0.0123 - precision: 1.0000 - recall: 0.9753 - val_loss: 0.7058 - val_accuracy: 0.6056 - val_mse: 0.3325 - val_precision: 0.5856 - val_recall: 0.7222 - lr: 1.0000e-07
Evaluating results...
Validation
[ 88  92]
[ 50 130]
Training
[810   0]
[ 20 790]

Total execution time:  6:10:20.190108
Final evalutaiton...
180/180 - 11s - loss: 0.7058 - accuracy: 0.6056 - mse: 0.3325 - precision: 0.5856 - recall: 0.7222
{'loss': 0.7057937383651733, 'accuracy': 0.605555534362793, 'mse': 0.3325481712818146, 'precision': 0.5855855941772461, 'recall': 0.7222222089767456}
