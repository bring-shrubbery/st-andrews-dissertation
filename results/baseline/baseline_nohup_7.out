WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
2020-08-02 12:04:03.032574: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-08-02 12:04:03.353431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 12:04:03.353980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 10 deviceMemorySize: 5.93GiB deviceMemoryBandwidth: 178.99GiB/s
2020-08-02 12:04:03.355894: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-08-02 12:04:03.360461: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-08-02 12:04:03.364407: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-08-02 12:04:03.364990: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-08-02 12:04:03.367801: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-08-02 12:04:03.369872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-08-02 12:04:03.374173: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-08-02 12:04:03.374331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 12:04:03.374691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 12:04:03.374950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-08-02 12:04:03.375210: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-08-02 12:04:03.381503: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3192000000 Hz
2020-08-02 12:04:03.381685: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xc6b637d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-02 12:04:03.381705: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-02 12:04:03.434402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 12:04:03.434846: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xc6b777c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-08-02 12:04:03.437274: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1060 6GB, Compute Capability 6.1
2020-08-02 12:04:03.439258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 12:04:03.439694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 10 deviceMemorySize: 5.93GiB deviceMemoryBandwidth: 178.99GiB/s
2020-08-02 12:04:03.439731: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-08-02 12:04:03.439750: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-08-02 12:04:03.439765: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-08-02 12:04:03.439780: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-08-02 12:04:03.439795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-08-02 12:04:03.439809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-08-02 12:04:03.439823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-08-02 12:04:03.439884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 12:04:03.440303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 12:04:03.440602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-08-02 12:04:03.442651: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-08-02 12:04:03.446133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-02 12:04:03.446155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-08-02 12:04:03.446167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-08-02 12:04:03.446295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 12:04:03.449002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-02 12:04:03.451462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5646 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-08-02 12:04:04.249150: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1698693120 exceeds 10% of free system memory.
2020-08-02 12:04:06.303115: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-08-02 12:04:06.420964: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-08-02 12:04:07.699083: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.78GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-02 12:04:07.801154: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-02 12:04:07.845038: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-02 12:04:07.953514: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-02 12:04:07.965332: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-02 12:04:07.993756: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.13GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-02 12:04:08.034218: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.11GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-02 12:04:08.224025: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.78GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-02 12:04:08.337263: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.78GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-02 12:07:47.610172: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1073741824 exceeds 10% of free system memory.
2020-08-02 12:07:49.184904: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1073741824 exceeds 10% of free system memory.
2020-08-02 12:07:49.916719: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1073741824 exceeds 10% of free system memory.
Preparing...
Loading dataset...
Creating the model...
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 502, 502, 96)      11712     
_________________________________________________________________
batch_normalization (BatchNo (None, 502, 502, 96)      384       
_________________________________________________________________
activation (Activation)      (None, 502, 502, 96)      0         
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 167, 167, 96)      0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 163, 163, 384)     921984    
_________________________________________________________________
activation_1 (Activation)    (None, 163, 163, 384)     0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 54, 54, 384)       0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 52, 52, 384)       1327488   
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 50, 50, 256)       884992    
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 48, 48, 256)       590080    
_________________________________________________________________
activation_2 (Activation)    (None, 48, 48, 256)       0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 16, 16, 256)       0         
_________________________________________________________________
flatten (Flatten)            (None, 65536)             0         
_________________________________________________________________
dense (Dense)                (None, 4096)              268439552 
_________________________________________________________________
dropout (Dropout)            (None, 4096)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 4096)              16781312  
_________________________________________________________________
dropout_1 (Dropout)          (None, 4096)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 4097      
=================================================================
Total params: 288,961,601
Trainable params: 288,961,409
Non-trainable params: 192
_________________________________________________________________
None
Training the model...
Epoch 1/100

Epoch 00001: val_loss improved from inf to 49.15088, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 225s - loss: 76.3521 - accuracy: 0.4994 - mse: 0.4694 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 49.1509 - val_accuracy: 0.5000 - val_mse: 0.4729 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05
2020-08-02 12:11:35.418672: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1073741824 exceeds 10% of free system memory.
Epoch 2/100

Epoch 00002: val_loss improved from 49.15088 to 20.16326, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 227s - loss: 32.8085 - accuracy: 0.5000 - mse: 0.4196 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 20.1633 - val_accuracy: 0.5000 - val_mse: 0.3522 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05
Epoch 3/100

Epoch 00003: val_loss improved from 20.16326 to 7.46240, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 227s - loss: 12.9194 - accuracy: 0.5389 - mse: 0.3642 - precision: 0.7890 - recall: 0.1062 - val_loss: 7.4624 - val_accuracy: 0.6250 - val_mse: 0.3503 - val_precision: 1.0000 - val_recall: 0.2500 - lr: 1.0000e-05
Epoch 4/100

Epoch 00004: val_loss improved from 7.46240 to 2.59632, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 227s - loss: 4.6269 - accuracy: 0.5969 - mse: 0.3434 - precision: 0.8054 - recall: 0.2556 - val_loss: 2.5963 - val_accuracy: 0.6389 - val_mse: 0.3350 - val_precision: 0.8049 - val_recall: 0.3667 - lr: 1.0000e-05
Epoch 5/100

Epoch 00005: val_loss improved from 2.59632 to 1.13457, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 229s - loss: 1.6781 - accuracy: 0.6191 - mse: 0.3280 - precision: 0.8410 - recall: 0.2938 - val_loss: 1.1346 - val_accuracy: 0.5750 - val_mse: 0.3572 - val_precision: 0.5882 - val_recall: 0.5000 - lr: 1.0000e-05
Epoch 6/100

Epoch 00006: val_loss improved from 1.13457 to 0.72667, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 229s - loss: 0.8562 - accuracy: 0.6457 - mse: 0.3176 - precision: 0.8576 - recall: 0.3494 - val_loss: 0.7267 - val_accuracy: 0.5972 - val_mse: 0.3438 - val_precision: 1.0000 - val_recall: 0.1944 - lr: 1.0000e-05
Epoch 7/100

Epoch 00007: val_loss improved from 0.72667 to 0.70262, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 227s - loss: 0.6836 - accuracy: 0.6679 - mse: 0.2928 - precision: 0.8560 - recall: 0.4037 - val_loss: 0.7026 - val_accuracy: 0.6194 - val_mse: 0.2911 - val_precision: 0.6405 - val_recall: 0.5444 - lr: 1.0000e-05
Epoch 8/100

Epoch 00008: val_loss improved from 0.70262 to 0.65269, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 227s - loss: 0.6589 - accuracy: 0.6716 - mse: 0.2808 - precision: 0.8639 - recall: 0.4074 - val_loss: 0.6527 - val_accuracy: 0.6861 - val_mse: 0.2576 - val_precision: 0.7724 - val_recall: 0.5278 - lr: 1.0000e-05
Epoch 9/100

Epoch 00009: val_loss improved from 0.65269 to 0.64519, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 227s - loss: 0.6458 - accuracy: 0.6951 - mse: 0.2714 - precision: 0.8892 - recall: 0.4457 - val_loss: 0.6452 - val_accuracy: 0.6944 - val_mse: 0.2576 - val_precision: 0.8182 - val_recall: 0.5000 - lr: 1.0000e-05
Epoch 10/100

Epoch 00010: val_loss improved from 0.64519 to 0.63968, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 228s - loss: 0.6412 - accuracy: 0.7056 - mse: 0.2660 - precision: 0.8863 - recall: 0.4716 - val_loss: 0.6397 - val_accuracy: 0.6806 - val_mse: 0.2956 - val_precision: 1.0000 - val_recall: 0.3611 - lr: 1.0000e-05
Epoch 11/100

Epoch 00011: val_loss improved from 0.63968 to 0.62172, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 228s - loss: 0.6375 - accuracy: 0.7086 - mse: 0.2588 - precision: 0.9005 - recall: 0.4691 - val_loss: 0.6217 - val_accuracy: 0.7417 - val_mse: 0.2362 - val_precision: 0.9394 - val_recall: 0.5167 - lr: 1.0000e-05
Epoch 12/100

Epoch 00012: val_loss did not improve from 0.62172
810/810 - 220s - loss: 0.6316 - accuracy: 0.7272 - mse: 0.2413 - precision: 0.8966 - recall: 0.5136 - val_loss: 0.6441 - val_accuracy: 0.6528 - val_mse: 0.3028 - val_precision: 1.0000 - val_recall: 0.3056 - lr: 1.0000e-05
Epoch 13/100

Epoch 00013: val_loss improved from 0.62172 to 0.61559, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 229s - loss: 0.6255 - accuracy: 0.7420 - mse: 0.2337 - precision: 0.9188 - recall: 0.5309 - val_loss: 0.6156 - val_accuracy: 0.7639 - val_mse: 0.2195 - val_precision: 0.9439 - val_recall: 0.5611 - lr: 1.0000e-05
Epoch 14/100

Epoch 00014: val_loss did not improve from 0.61559
810/810 - 220s - loss: 0.6195 - accuracy: 0.7586 - mse: 0.2227 - precision: 0.9374 - recall: 0.5543 - val_loss: 0.6159 - val_accuracy: 0.7444 - val_mse: 0.2384 - val_precision: 1.0000 - val_recall: 0.4889 - lr: 1.0000e-05
Epoch 15/100

Epoch 00015: val_loss improved from 0.61559 to 0.61272, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 229s - loss: 0.6177 - accuracy: 0.7623 - mse: 0.2105 - precision: 0.9242 - recall: 0.5716 - val_loss: 0.6127 - val_accuracy: 0.7583 - val_mse: 0.2108 - val_precision: 0.9189 - val_recall: 0.5667 - lr: 1.0000e-05
Epoch 16/100

Epoch 00016: val_loss did not improve from 0.61272
810/810 - 220s - loss: 0.6125 - accuracy: 0.7784 - mse: 0.1971 - precision: 0.9362 - recall: 0.5975 - val_loss: 0.6198 - val_accuracy: 0.7639 - val_mse: 0.2205 - val_precision: 0.8992 - val_recall: 0.5944 - lr: 1.0000e-05
Epoch 17/100

Epoch 00017: val_loss did not improve from 0.61272
810/810 - 221s - loss: 0.6081 - accuracy: 0.7864 - mse: 0.1900 - precision: 0.9394 - recall: 0.6123 - val_loss: 0.6246 - val_accuracy: 0.7306 - val_mse: 0.2519 - val_precision: 1.0000 - val_recall: 0.4611 - lr: 1.0000e-05
Epoch 18/100

Epoch 00018: val_loss improved from 0.61272 to 0.60882, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 227s - loss: 0.6036 - accuracy: 0.8019 - mse: 0.1809 - precision: 0.9553 - recall: 0.6333 - val_loss: 0.6088 - val_accuracy: 0.7889 - val_mse: 0.2002 - val_precision: 0.9262 - val_recall: 0.6278 - lr: 1.0000e-05
Epoch 19/100

Epoch 00019: val_loss did not improve from 0.60882
810/810 - 220s - loss: 0.5979 - accuracy: 0.8130 - mse: 0.1671 - precision: 0.9584 - recall: 0.6543 - val_loss: 0.6113 - val_accuracy: 0.7833 - val_mse: 0.1830 - val_precision: 0.8592 - val_recall: 0.6778 - lr: 1.0000e-05
Epoch 20/100

Epoch 00020: val_loss did not improve from 0.60882
810/810 - 220s - loss: 0.5962 - accuracy: 0.8247 - mse: 0.1629 - precision: 0.9614 - recall: 0.6765 - val_loss: 0.6216 - val_accuracy: 0.7333 - val_mse: 0.2258 - val_precision: 0.9773 - val_recall: 0.4778 - lr: 1.0000e-05
Epoch 21/100

Epoch 00021: val_loss did not improve from 0.60882
810/810 - 220s - loss: 0.5888 - accuracy: 0.8414 - mse: 0.1474 - precision: 0.9859 - recall: 0.6926 - val_loss: 0.6102 - val_accuracy: 0.7694 - val_mse: 0.2083 - val_precision: 1.0000 - val_recall: 0.5389 - lr: 1.0000e-05
Epoch 22/100

Epoch 00022: val_loss did not improve from 0.60882
810/810 - 220s - loss: 0.5872 - accuracy: 0.8432 - mse: 0.1448 - precision: 0.9777 - recall: 0.7025 - val_loss: 0.6251 - val_accuracy: 0.7194 - val_mse: 0.2316 - val_precision: 0.9438 - val_recall: 0.4667 - lr: 1.0000e-05
Epoch 23/100

Epoch 00023: val_loss did not improve from 0.60882
810/810 - 220s - loss: 0.5845 - accuracy: 0.8481 - mse: 0.1405 - precision: 0.9780 - recall: 0.7123 - val_loss: 0.6642 - val_accuracy: 0.6139 - val_mse: 0.3466 - val_precision: 1.0000 - val_recall: 0.2278 - lr: 1.0000e-05
Epoch 24/100

Epoch 00024: val_loss improved from 0.60882 to 0.59975, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 228s - loss: 0.5826 - accuracy: 0.8556 - mse: 0.1341 - precision: 0.9737 - recall: 0.7309 - val_loss: 0.5998 - val_accuracy: 0.8278 - val_mse: 0.1583 - val_precision: 0.8882 - val_recall: 0.7500 - lr: 1.0000e-05
Epoch 25/100

Epoch 00025: val_loss did not improve from 0.59975
810/810 - 220s - loss: 0.5796 - accuracy: 0.8654 - mse: 0.1256 - precision: 0.9744 - recall: 0.7506 - val_loss: 0.6198 - val_accuracy: 0.7694 - val_mse: 0.1985 - val_precision: 0.8392 - val_recall: 0.6667 - lr: 1.0000e-05
Epoch 26/100

Epoch 00026: val_loss did not improve from 0.59975
810/810 - 220s - loss: 0.5756 - accuracy: 0.8728 - mse: 0.1166 - precision: 0.9824 - recall: 0.7593 - val_loss: 0.6150 - val_accuracy: 0.7833 - val_mse: 0.1890 - val_precision: 0.8446 - val_recall: 0.6944 - lr: 1.0000e-05
Epoch 27/100

Epoch 00027: val_loss improved from 0.59975 to 0.59964, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 227s - loss: 0.5726 - accuracy: 0.8821 - mse: 0.1110 - precision: 0.9769 - recall: 0.7827 - val_loss: 0.5996 - val_accuracy: 0.8167 - val_mse: 0.1557 - val_precision: 0.8904 - val_recall: 0.7222 - lr: 1.0000e-05
Epoch 28/100

Epoch 00028: val_loss improved from 0.59964 to 0.59838, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 227s - loss: 0.5709 - accuracy: 0.8864 - mse: 0.1091 - precision: 0.9830 - recall: 0.7864 - val_loss: 0.5984 - val_accuracy: 0.8194 - val_mse: 0.1667 - val_precision: 0.9259 - val_recall: 0.6944 - lr: 1.0000e-05
Epoch 29/100

Epoch 00029: val_loss improved from 0.59838 to 0.59180, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 228s - loss: 0.5678 - accuracy: 0.8944 - mse: 0.1005 - precision: 0.9863 - recall: 0.8000 - val_loss: 0.5918 - val_accuracy: 0.8167 - val_mse: 0.1561 - val_precision: 0.9385 - val_recall: 0.6778 - lr: 1.0000e-05
Epoch 30/100

Epoch 00030: val_loss did not improve from 0.59180
810/810 - 220s - loss: 0.5644 - accuracy: 0.9012 - mse: 0.0964 - precision: 0.9909 - recall: 0.8099 - val_loss: 0.6039 - val_accuracy: 0.8139 - val_mse: 0.1535 - val_precision: 0.8599 - val_recall: 0.7500 - lr: 1.0000e-05
Epoch 31/100

Epoch 00031: val_loss did not improve from 0.59180
810/810 - 220s - loss: 0.5635 - accuracy: 0.9025 - mse: 0.0938 - precision: 0.9895 - recall: 0.8136 - val_loss: 0.6250 - val_accuracy: 0.7806 - val_mse: 0.1841 - val_precision: 0.7790 - val_recall: 0.7833 - lr: 1.0000e-05
Epoch 32/100

Epoch 00032: val_loss did not improve from 0.59180
810/810 - 220s - loss: 0.5641 - accuracy: 0.9019 - mse: 0.0953 - precision: 0.9895 - recall: 0.8123 - val_loss: 0.6151 - val_accuracy: 0.8028 - val_mse: 0.1723 - val_precision: 0.8114 - val_recall: 0.7889 - lr: 1.0000e-05
Epoch 33/100

Epoch 00033: val_loss did not improve from 0.59180
810/810 - 220s - loss: 0.5617 - accuracy: 0.9037 - mse: 0.0910 - precision: 0.9866 - recall: 0.8185 - val_loss: 0.6004 - val_accuracy: 0.7778 - val_mse: 0.1816 - val_precision: 0.9310 - val_recall: 0.6000 - lr: 1.0000e-05
Epoch 34/100

Epoch 00034: val_loss did not improve from 0.59180
810/810 - 220s - loss: 0.5594 - accuracy: 0.9086 - mse: 0.0883 - precision: 0.9896 - recall: 0.8259 - val_loss: 0.6018 - val_accuracy: 0.7944 - val_mse: 0.1651 - val_precision: 0.8897 - val_recall: 0.6722 - lr: 1.0000e-05
Epoch 35/100

Epoch 00035: val_loss did not improve from 0.59180
810/810 - 220s - loss: 0.5574 - accuracy: 0.9123 - mse: 0.0856 - precision: 0.9912 - recall: 0.8321 - val_loss: 0.6102 - val_accuracy: 0.8111 - val_mse: 0.1740 - val_precision: 0.8457 - val_recall: 0.7611 - lr: 1.0000e-05
Epoch 36/100

Epoch 00036: val_loss did not improve from 0.59180
810/810 - 220s - loss: 0.5565 - accuracy: 0.9136 - mse: 0.0837 - precision: 0.9926 - recall: 0.8333 - val_loss: 0.6277 - val_accuracy: 0.7778 - val_mse: 0.1995 - val_precision: 0.7907 - val_recall: 0.7556 - lr: 1.0000e-05
Epoch 37/100

Epoch 00037: val_loss did not improve from 0.59180
810/810 - 219s - loss: 0.5569 - accuracy: 0.9130 - mse: 0.0836 - precision: 0.9926 - recall: 0.8321 - val_loss: 0.6003 - val_accuracy: 0.8139 - val_mse: 0.1605 - val_precision: 0.8693 - val_recall: 0.7389 - lr: 1.0000e-05
Epoch 38/100

Epoch 00038: val_loss did not improve from 0.59180
810/810 - 220s - loss: 0.5542 - accuracy: 0.9173 - mse: 0.0795 - precision: 0.9884 - recall: 0.8444 - val_loss: 0.5985 - val_accuracy: 0.8222 - val_mse: 0.1639 - val_precision: 0.9028 - val_recall: 0.7222 - lr: 1.0000e-05
Epoch 39/100

Epoch 00039: val_loss did not improve from 0.59180

Epoch 00039: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.
810/810 - 219s - loss: 0.5529 - accuracy: 0.9204 - mse: 0.0789 - precision: 0.9928 - recall: 0.8469 - val_loss: 0.6238 - val_accuracy: 0.7917 - val_mse: 0.1886 - val_precision: 0.7869 - val_recall: 0.8000 - lr: 1.0000e-05
Epoch 40/100

Epoch 00040: val_loss did not improve from 0.59180
810/810 - 219s - loss: 0.5511 - accuracy: 0.9228 - mse: 0.0770 - precision: 0.9942 - recall: 0.8506 - val_loss: 0.6025 - val_accuracy: 0.8111 - val_mse: 0.1674 - val_precision: 0.8684 - val_recall: 0.7333 - lr: 1.0000e-06
Epoch 41/100

Epoch 00041: val_loss did not improve from 0.59180
810/810 - 219s - loss: 0.5503 - accuracy: 0.9222 - mse: 0.0770 - precision: 0.9942 - recall: 0.8494 - val_loss: 0.6036 - val_accuracy: 0.8139 - val_mse: 0.1689 - val_precision: 0.8693 - val_recall: 0.7389 - lr: 1.0000e-06
Epoch 42/100

Epoch 00042: val_loss did not improve from 0.59180
810/810 - 220s - loss: 0.5493 - accuracy: 0.9241 - mse: 0.0753 - precision: 0.9942 - recall: 0.8531 - val_loss: 0.6053 - val_accuracy: 0.8083 - val_mse: 0.1740 - val_precision: 0.8675 - val_recall: 0.7278 - lr: 1.0000e-06
Epoch 43/100

Epoch 00043: val_loss did not improve from 0.59180
810/810 - 220s - loss: 0.5488 - accuracy: 0.9241 - mse: 0.0749 - precision: 0.9942 - recall: 0.8531 - val_loss: 0.6031 - val_accuracy: 0.8139 - val_mse: 0.1729 - val_precision: 0.8792 - val_recall: 0.7278 - lr: 1.0000e-06
Epoch 44/100

Epoch 00044: val_loss did not improve from 0.59180
810/810 - 220s - loss: 0.5485 - accuracy: 0.9247 - mse: 0.0750 - precision: 0.9943 - recall: 0.8543 - val_loss: 0.6103 - val_accuracy: 0.8028 - val_mse: 0.1807 - val_precision: 0.8471 - val_recall: 0.7389 - lr: 1.0000e-06
Epoch 45/100

Epoch 00045: val_loss did not improve from 0.59180
810/810 - 220s - loss: 0.5488 - accuracy: 0.9235 - mse: 0.0759 - precision: 0.9942 - recall: 0.8519 - val_loss: 0.6101 - val_accuracy: 0.8056 - val_mse: 0.1788 - val_precision: 0.8526 - val_recall: 0.7389 - lr: 1.0000e-06
Epoch 46/100

Epoch 00046: val_loss did not improve from 0.59180
810/810 - 219s - loss: 0.5485 - accuracy: 0.9235 - mse: 0.0759 - precision: 0.9942 - recall: 0.8519 - val_loss: 0.6176 - val_accuracy: 0.7917 - val_mse: 0.1920 - val_precision: 0.8221 - val_recall: 0.7444 - lr: 1.0000e-06
Epoch 47/100

Epoch 00047: val_loss did not improve from 0.59180
810/810 - 220s - loss: 0.5478 - accuracy: 0.9241 - mse: 0.0750 - precision: 0.9942 - recall: 0.8531 - val_loss: 0.6272 - val_accuracy: 0.7833 - val_mse: 0.2027 - val_precision: 0.8036 - val_recall: 0.7500 - lr: 1.0000e-06
Epoch 48/100

Epoch 00048: val_loss did not improve from 0.59180
810/810 - 219s - loss: 0.5478 - accuracy: 0.9259 - mse: 0.0744 - precision: 0.9943 - recall: 0.8568 - val_loss: 0.6186 - val_accuracy: 0.7917 - val_mse: 0.1948 - val_precision: 0.8261 - val_recall: 0.7389 - lr: 1.0000e-06
Epoch 49/100

Epoch 00049: val_loss did not improve from 0.59180

Epoch 00049: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.
810/810 - 220s - loss: 0.5476 - accuracy: 0.9235 - mse: 0.0751 - precision: 0.9942 - recall: 0.8519 - val_loss: 0.6114 - val_accuracy: 0.7972 - val_mse: 0.1832 - val_precision: 0.8452 - val_recall: 0.7278 - lr: 1.0000e-06
Epoch 00049: early stopping
Evaluating results...
Validation
[156  24]
[ 49 131]
Training
[806   4]
[116 694]

Total execution time:  3:03:23.534585
Final evalutaiton...
180/180 - 11s - loss: 0.6114 - accuracy: 0.7972 - mse: 0.1832 - precision: 0.8452 - recall: 0.7278
{'loss': 0.6113989949226379, 'accuracy': 0.7972221970558167, 'mse': 0.1831943541765213, 'precision': 0.8451613187789917, 'recall': 0.7277777791023254}
