WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
2020-08-11 16:39:26.868422: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1698693120 exceeds 10% of free system memory.
2020-08-11 16:39:29.492121: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.78GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-11 16:39:29.593968: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-11 16:39:29.634047: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-11 16:39:29.742082: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-11 16:39:29.813300: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-11 16:39:29.843263: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.13GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-11 16:39:29.883814: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.11GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-11 16:39:30.073697: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.78GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-11 16:39:30.188387: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.78GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-08-11 16:43:09.670294: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1073741824 exceeds 10% of free system memory.
2020-08-11 16:43:10.742244: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1073741824 exceeds 10% of free system memory.
2020-08-11 16:43:11.033716: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1073741824 exceeds 10% of free system memory.
Preparing...
Loading dataset...
4893.004670274749 -3230.518254521652
4863.728119230238 -3309.0571501744225
1.0 0.0
1.0 0.0
Creating the model...
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 502, 502, 96)      11712     
_________________________________________________________________
batch_normalization (BatchNo (None, 502, 502, 96)      384       
_________________________________________________________________
activation (Activation)      (None, 502, 502, 96)      0         
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 167, 167, 96)      0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 163, 163, 384)     921984    
_________________________________________________________________
activation_1 (Activation)    (None, 163, 163, 384)     0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 54, 54, 384)       0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 52, 52, 384)       1327488   
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 50, 50, 256)       884992    
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 48, 48, 256)       590080    
_________________________________________________________________
activation_2 (Activation)    (None, 48, 48, 256)       0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 16, 16, 256)       0         
_________________________________________________________________
flatten (Flatten)            (None, 65536)             0         
_________________________________________________________________
dense (Dense)                (None, 4096)              268439552 
_________________________________________________________________
dropout (Dropout)            (None, 4096)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 4096)              16781312  
_________________________________________________________________
dropout_1 (Dropout)          (None, 4096)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 4097      
=================================================================
Total params: 288,961,601
Trainable params: 288,961,409
Non-trainable params: 192
_________________________________________________________________
None
Training the model...
Epoch 1/100

Epoch 00001: val_loss improved from inf to 49.06637, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 223s - loss: 76.2252 - accuracy: 0.4988 - mse: 0.4160 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 49.0664 - val_accuracy: 0.5000 - val_mse: 0.3804 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05
2020-08-11 16:46:54.179843: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1073741824 exceeds 10% of free system memory.
Epoch 2/100

Epoch 00002: val_loss improved from 49.06637 to 20.18735, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 224s - loss: 32.7824 - accuracy: 0.5093 - mse: 0.3777 - precision: 0.8000 - recall: 0.0247 - val_loss: 20.1873 - val_accuracy: 0.5000 - val_mse: 0.3807 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05
Epoch 3/100

Epoch 00003: val_loss improved from 20.18735 to 7.53089, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 224s - loss: 12.9565 - accuracy: 0.5525 - mse: 0.3417 - precision: 0.7852 - recall: 0.1444 - val_loss: 7.5309 - val_accuracy: 0.5528 - val_mse: 0.3415 - val_precision: 1.0000 - val_recall: 0.1056 - lr: 1.0000e-05
Epoch 4/100

Epoch 00004: val_loss improved from 7.53089 to 2.68500, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 224s - loss: 4.7033 - accuracy: 0.5735 - mse: 0.3639 - precision: 0.7717 - recall: 0.2086 - val_loss: 2.6850 - val_accuracy: 0.5444 - val_mse: 0.4074 - val_precision: 1.0000 - val_recall: 0.0889 - lr: 1.0000e-05
Epoch 5/100

Epoch 00005: val_loss improved from 2.68500 to 1.13355, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 224s - loss: 1.7441 - accuracy: 0.6043 - mse: 0.3275 - precision: 0.8007 - recall: 0.2778 - val_loss: 1.1335 - val_accuracy: 0.5639 - val_mse: 0.3351 - val_precision: 0.8710 - val_recall: 0.1500 - lr: 1.0000e-05
Epoch 6/100

Epoch 00006: val_loss improved from 1.13355 to 0.80090, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 225s - loss: 0.9076 - accuracy: 0.6222 - mse: 0.3184 - precision: 0.7946 - recall: 0.3296 - val_loss: 0.8009 - val_accuracy: 0.5111 - val_mse: 0.4673 - val_precision: 1.0000 - val_recall: 0.0222 - lr: 1.0000e-05
Epoch 7/100

Epoch 00007: val_loss improved from 0.80090 to 0.68027, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 224s - loss: 0.7235 - accuracy: 0.6432 - mse: 0.3092 - precision: 0.8204 - recall: 0.3667 - val_loss: 0.6803 - val_accuracy: 0.7389 - val_mse: 0.1736 - val_precision: 0.7529 - val_recall: 0.7111 - lr: 1.0000e-05
Epoch 8/100

Epoch 00008: val_loss did not improve from 0.68027
810/810 - 220s - loss: 0.6912 - accuracy: 0.6340 - mse: 0.3199 - precision: 0.8318 - recall: 0.3358 - val_loss: 0.7149 - val_accuracy: 0.5194 - val_mse: 0.4545 - val_precision: 1.0000 - val_recall: 0.0389 - lr: 1.0000e-05
Epoch 9/100

Epoch 00009: val_loss did not improve from 0.68027
810/810 - 220s - loss: 0.6695 - accuracy: 0.6735 - mse: 0.2983 - precision: 0.9003 - recall: 0.3901 - val_loss: 0.6924 - val_accuracy: 0.5833 - val_mse: 0.4017 - val_precision: 1.0000 - val_recall: 0.1667 - lr: 1.0000e-05
Epoch 10/100

Epoch 00010: val_loss did not improve from 0.68027
810/810 - 220s - loss: 0.6709 - accuracy: 0.6475 - mse: 0.3199 - precision: 0.8770 - recall: 0.3432 - val_loss: 0.7049 - val_accuracy: 0.5250 - val_mse: 0.4526 - val_precision: 1.0000 - val_recall: 0.0500 - lr: 1.0000e-05
Epoch 11/100

Epoch 00011: val_loss did not improve from 0.68027
810/810 - 219s - loss: 0.6573 - accuracy: 0.6753 - mse: 0.2823 - precision: 0.8679 - recall: 0.4136 - val_loss: 0.6985 - val_accuracy: 0.5389 - val_mse: 0.4368 - val_precision: 1.0000 - val_recall: 0.0778 - lr: 1.0000e-05
Epoch 12/100

Epoch 00012: val_loss did not improve from 0.68027
810/810 - 220s - loss: 0.6518 - accuracy: 0.6951 - mse: 0.2692 - precision: 0.8726 - recall: 0.4568 - val_loss: 0.7033 - val_accuracy: 0.5250 - val_mse: 0.4556 - val_precision: 1.0000 - val_recall: 0.0500 - lr: 1.0000e-05
Epoch 13/100

Epoch 00013: val_loss did not improve from 0.68027
810/810 - 218s - loss: 0.6477 - accuracy: 0.7006 - mse: 0.2645 - precision: 0.8806 - recall: 0.4642 - val_loss: 0.6971 - val_accuracy: 0.5361 - val_mse: 0.4397 - val_precision: 1.0000 - val_recall: 0.0722 - lr: 1.0000e-05
Epoch 14/100

Epoch 00014: val_loss did not improve from 0.68027
810/810 - 220s - loss: 0.6417 - accuracy: 0.7074 - mse: 0.2578 - precision: 0.9019 - recall: 0.4654 - val_loss: 0.6919 - val_accuracy: 0.5500 - val_mse: 0.4223 - val_precision: 1.0000 - val_recall: 0.1000 - lr: 1.0000e-05
Epoch 15/100

Epoch 00015: val_loss improved from 0.68027 to 0.64817, saving model to /cs/scratch/as521/models/checkpoints/baseline-model.h5
810/810 - 227s - loss: 0.6328 - accuracy: 0.7352 - mse: 0.2382 - precision: 0.9400 - recall: 0.5025 - val_loss: 0.6482 - val_accuracy: 0.7139 - val_mse: 0.2404 - val_precision: 0.8080 - val_recall: 0.5611 - lr: 1.0000e-05
Epoch 16/100

Epoch 00016: val_loss did not improve from 0.64817
810/810 - 220s - loss: 0.6292 - accuracy: 0.7469 - mse: 0.2260 - precision: 0.9237 - recall: 0.5383 - val_loss: 0.6781 - val_accuracy: 0.5972 - val_mse: 0.3737 - val_precision: 0.9487 - val_recall: 0.2056 - lr: 1.0000e-05
Epoch 17/100

Epoch 00017: val_loss did not improve from 0.64817
810/810 - 220s - loss: 0.6226 - accuracy: 0.7642 - mse: 0.2107 - precision: 0.9350 - recall: 0.5679 - val_loss: 0.6900 - val_accuracy: 0.5639 - val_mse: 0.4090 - val_precision: 0.8710 - val_recall: 0.1500 - lr: 1.0000e-05
Epoch 18/100

Epoch 00018: val_loss did not improve from 0.64817
810/810 - 219s - loss: 0.6184 - accuracy: 0.7765 - mse: 0.2015 - precision: 0.9444 - recall: 0.5877 - val_loss: 0.6541 - val_accuracy: 0.6750 - val_mse: 0.2773 - val_precision: 0.8462 - val_recall: 0.4278 - lr: 1.0000e-05
Epoch 19/100

Epoch 00019: val_loss did not improve from 0.64817
810/810 - 219s - loss: 0.6148 - accuracy: 0.7840 - mse: 0.1907 - precision: 0.9492 - recall: 0.6000 - val_loss: 0.6782 - val_accuracy: 0.5944 - val_mse: 0.3739 - val_precision: 0.9474 - val_recall: 0.2000 - lr: 1.0000e-05
Epoch 20/100

Epoch 00020: val_loss did not improve from 0.64817
810/810 - 219s - loss: 0.6076 - accuracy: 0.8117 - mse: 0.1707 - precision: 0.9533 - recall: 0.6556 - val_loss: 0.6596 - val_accuracy: 0.6639 - val_mse: 0.3115 - val_precision: 0.9403 - val_recall: 0.3500 - lr: 1.0000e-05
Epoch 21/100

Epoch 00021: val_loss did not improve from 0.64817
810/810 - 219s - loss: 0.6005 - accuracy: 0.8278 - mse: 0.1590 - precision: 0.9666 - recall: 0.6790 - val_loss: 0.6636 - val_accuracy: 0.6500 - val_mse: 0.3299 - val_precision: 0.9355 - val_recall: 0.3222 - lr: 1.0000e-05
Epoch 22/100

Epoch 00022: val_loss did not improve from 0.64817
810/810 - 219s - loss: 0.5984 - accuracy: 0.8358 - mse: 0.1527 - precision: 0.9658 - recall: 0.6963 - val_loss: 0.6781 - val_accuracy: 0.6083 - val_mse: 0.3678 - val_precision: 0.9149 - val_recall: 0.2389 - lr: 1.0000e-05
Epoch 23/100

Epoch 00023: val_loss did not improve from 0.64817
810/810 - 219s - loss: 0.5939 - accuracy: 0.8414 - mse: 0.1458 - precision: 0.9743 - recall: 0.7012 - val_loss: 0.6688 - val_accuracy: 0.6222 - val_mse: 0.3421 - val_precision: 0.9231 - val_recall: 0.2667 - lr: 1.0000e-05
Epoch 24/100

Epoch 00024: val_loss did not improve from 0.64817
810/810 - 219s - loss: 0.5885 - accuracy: 0.8519 - mse: 0.1366 - precision: 0.9863 - recall: 0.7136 - val_loss: 0.6619 - val_accuracy: 0.6694 - val_mse: 0.3155 - val_precision: 0.9067 - val_recall: 0.3778 - lr: 1.0000e-05
Epoch 25/100

Epoch 00025: val_loss did not improve from 0.64817

Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.
810/810 - 219s - loss: 0.5856 - accuracy: 0.8636 - mse: 0.1291 - precision: 0.9852 - recall: 0.7383 - val_loss: 0.6643 - val_accuracy: 0.6333 - val_mse: 0.3303 - val_precision: 0.9286 - val_recall: 0.2889 - lr: 1.0000e-05
Epoch 26/100

Epoch 00026: val_loss did not improve from 0.64817
810/810 - 219s - loss: 0.5777 - accuracy: 0.8765 - mse: 0.1182 - precision: 0.9919 - recall: 0.7593 - val_loss: 0.6609 - val_accuracy: 0.6444 - val_mse: 0.3172 - val_precision: 0.9194 - val_recall: 0.3167 - lr: 1.0000e-06
Epoch 27/100

Epoch 00027: val_loss did not improve from 0.64817
810/810 - 219s - loss: 0.5763 - accuracy: 0.8790 - mse: 0.1156 - precision: 0.9968 - recall: 0.7605 - val_loss: 0.6583 - val_accuracy: 0.6611 - val_mse: 0.3073 - val_precision: 0.9028 - val_recall: 0.3611 - lr: 1.0000e-06
Epoch 28/100

Epoch 00028: val_loss did not improve from 0.64817
810/810 - 219s - loss: 0.5758 - accuracy: 0.8802 - mse: 0.1145 - precision: 0.9952 - recall: 0.7642 - val_loss: 0.6618 - val_accuracy: 0.6361 - val_mse: 0.3181 - val_precision: 0.8889 - val_recall: 0.3111 - lr: 1.0000e-06
Epoch 29/100

Epoch 00029: val_loss did not improve from 0.64817
810/810 - 218s - loss: 0.5743 - accuracy: 0.8852 - mse: 0.1106 - precision: 0.9952 - recall: 0.7741 - val_loss: 0.6632 - val_accuracy: 0.6306 - val_mse: 0.3226 - val_precision: 0.8730 - val_recall: 0.3056 - lr: 1.0000e-06
Epoch 30/100

Epoch 00030: val_loss did not improve from 0.64817
810/810 - 219s - loss: 0.5735 - accuracy: 0.8864 - mse: 0.1098 - precision: 0.9968 - recall: 0.7753 - val_loss: 0.6540 - val_accuracy: 0.6833 - val_mse: 0.2949 - val_precision: 0.9024 - val_recall: 0.4111 - lr: 1.0000e-06
Epoch 00030: early stopping
Evaluating results...
Validation
[172   8]
[106  74]
Training
[808   2]
[179 631]

Total execution time:  1:51:48.658918
Final evalutaiton...
180/180 - 11s - loss: 0.6540 - accuracy: 0.6833 - mse: 0.2949 - precision: 0.9024 - recall: 0.4111
{'loss': 0.6540499329566956, 'accuracy': 0.6833333373069763, 'mse': 0.2948682904243469, 'precision': 0.9024389982223511, 'recall': 0.41111111640930176}
